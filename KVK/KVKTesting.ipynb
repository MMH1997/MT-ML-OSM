{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d917564",
   "metadata": {},
   "source": [
    "### We import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82eabf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d257f59",
   "metadata": {},
   "source": [
    "### We load datasets of tags from different cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1942d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "buiP = pd.read_csv('buildingP3.csv', delimiter=\";\")\n",
    "buiP = buiP.iloc[:,0:5]\n",
    "ameP = pd.read_csv('amenityP3.csv', delimiter=\";\")\n",
    "ameP = ameP.iloc[:,0:5]\n",
    "touP = pd.read_csv('highwayP3.csv', delimiter=\";\")\n",
    "touP = touP.iloc[:,0:5]\n",
    "higp = pd.read_csv('tourismP3.csv', delimiter=\";\")\n",
    "higp = higp.iloc[:,0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47b448fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Paris = buiP.append(ameP, ignore_index=True)\n",
    "Paris = Paris.append(touP, ignore_index = True)\n",
    "Paris = Paris.append(higp, ignore_index = True)\n",
    "Paris.to_csv('Paris.csv', index = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed5031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "buiBr = pd.read_csv('buildingBr3.csv', delimiter=\";\")\n",
    "buiBr = buiBr.iloc[:,0:5]\n",
    "ameBr = pd.read_csv('amenityBr3.csv', delimiter=\";\")\n",
    "ameBr = ameBr.iloc[:,0:5]\n",
    "touBr = pd.read_csv('tourismBr3.csv', delimiter=\";\")\n",
    "touBr = touBr.iloc[:,0:5]\n",
    "higBr = pd.read_csv('highwayBr3.csv', delimiter=\";\")\n",
    "higBr = higBr.iloc[:,0:5]\n",
    "Bruselas = buiBr.append(ameBr, ignore_index=True)\n",
    "Bruselas = Bruselas.append(touBr, ignore_index = True)\n",
    "Bruselas = Bruselas.append(higBr, ignore_index = True)\n",
    "Bruselas = Bruselas.drop(Bruselas[(Bruselas['error'] != 'no') & (Bruselas['error'] != 'yes')].index)\n",
    "Bruselas.to_csv('Bruselas.csv', index = False)  \n",
    "Bruselas = pd.read_csv('Bruselas.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dea1425",
   "metadata": {},
   "outputs": [],
   "source": [
    "buiB = pd.read_csv('buildingB3.csv', delimiter=\";\")\n",
    "buiB = buiB.iloc[:,0:5]\n",
    "ameB = pd.read_csv('amenityB3.csv', delimiter=\";\")\n",
    "ameB = ameB.iloc[:,0:5]\n",
    "touB = pd.read_csv('highwayB3.csv', delimiter=\";\")\n",
    "touB = touB.iloc[:,0:5]\n",
    "higB = pd.read_csv('tourismB3.csv', delimiter=\";\")\n",
    "higB = higB.iloc[:,0:5]\n",
    "Barcelona = buiB.append(ameB, ignore_index=True)\n",
    "Barcelona = Barcelona.append(touB, ignore_index = True)\n",
    "Barcelona = Barcelona.append(higB, ignore_index = True)\n",
    "Barcelona.to_csv('Barcelona.csv', index = False)  \n",
    "Barcelona = pd.read_csv('Barcelona.csv', delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daa8eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "buiH = pd.read_csv('buildingH3.csv', delimiter=\";\")\n",
    "buiH = buiH.iloc[:,0:5]\n",
    "ameH = pd.read_csv('amenityH3.csv', delimiter=\";\")\n",
    "ameH = ameH.iloc[:,0:5]\n",
    "touH = pd.read_csv('highwayH3.csv', delimiter=\";\")\n",
    "touH = touH.iloc[:,0:5]\n",
    "higH = pd.read_csv('tourismH3.csv', delimiter=\";\")\n",
    "higH = higH.iloc[:,0:5]\n",
    "Habana = buiH.append(ameH, ignore_index=True)\n",
    "Habana = Habana.append(touH, ignore_index = True)\n",
    "Habana = Habana.append(higH, ignore_index = True)\n",
    "Habana.to_csv('Habana.csv', index = False)  \n",
    "Habana = pd.read_csv('Habana.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0838dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buiBo = pd.read_csv('buildingBo3.csv', delimiter=\";\")\n",
    "# buiBo = buiBo.iloc[:,0:5]\n",
    "# ameBo = pd.read_csv('amenityBo3.csv', delimiter=\";\")\n",
    "# ameBo = ameBo.iloc[:,0:5]\n",
    "# touBo = pd.read_csv('highwayBo3.csv', delimiter=\";\")\n",
    "# touBo = touBo.iloc[:,0:5]\n",
    "# higBo = pd.read_csv('tourismBo3.csv', delimiter=\";\")\n",
    "# higBo = higBo.iloc[:,0:5]\n",
    "# Boston = buiBo.append(ameBo, ignore_index=True)\n",
    "# Boston = Boston.append(touBo, ignore_index = True)\n",
    "# Boston = Boston.append(higBo, ignore_index = True)\n",
    "# Boston.to_csv('Boston.csv', index = False)  \n",
    "Boston = pd.read_csv('Boston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52324888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buiSC = pd.read_csv('buildingSC3.csv', delimiter=\";\")\n",
    "# buiSC = buiSC.iloc[:,0:5]\n",
    "# ameSC = pd.read_csv('amenitySC3.csv', delimiter=\";\")\n",
    "# ameSC = ameSC.iloc[:,0:5]\n",
    "# touSC = pd.read_csv('highwaySC3.csv', delimiter=\";\")\n",
    "# touSC = touSC.iloc[:,0:5]\n",
    "# higSC = pd.read_csv('tourismSC3.csv', delimiter=\";\")\n",
    "# higSC = higSC.iloc[:,0:5]\n",
    "# SChile = buiSC.append(ameSC, ignore_index=True)\n",
    "# SChile = SChile.append(touSC, ignore_index = True)\n",
    "# SChile = SChile.append(higSC, ignore_index = True)\n",
    "# SChile.to_csv('SChile.csv', index = False)  \n",
    "SChile = pd.read_csv('SChile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73fc34a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buiLu = pd.read_csv('buildingLu3.csv', delimiter=\";\")\n",
    "# buiLu = buiLu.iloc[:,0:5]\n",
    "# ameLu = pd.read_csv('amenityLu3.csv', delimiter=\";\")\n",
    "# ameLu = ameLu.iloc[:,0:5]\n",
    "# touLu = pd.read_csv('highwayLu3.csv', delimiter=\";\")\n",
    "# touLu = touLu.iloc[:,0:5]\n",
    "# higLu = pd.read_csv('tourismLu3.csv', delimiter=\";\")\n",
    "# higLu = higLu.iloc[:,0:5]\n",
    "# Luanda = buiLu.append(ameLu, ignore_index=True)\n",
    "# Luanda = Luanda.append(touLu, ignore_index = True)\n",
    "# Luanda = Luanda.append(higLu, ignore_index = True)\n",
    "# Luanda.to_csv('Luanda.csv', index = False)  \n",
    "Luanda = pd.read_csv('Luanda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47cef8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buiWu = pd.read_csv('buildingWu3.csv', delimiter=\";\")\n",
    "# buiWu = buiWu.iloc[:,0:5]\n",
    "# ameWu = pd.read_csv('amenityWu3.csv', delimiter=\";\")\n",
    "# ameWu = ameWu.iloc[:,0:5]\n",
    "# touWu = pd.read_csv('highwayWu3.csv', delimiter=\";\")\n",
    "# touWu = touWu.iloc[:,0:5]\n",
    "# higWu = pd.read_csv('tourismWu3.csv', delimiter=\";\")\n",
    "# higWu = higWu.iloc[:,0:5]\n",
    "# Wuhan = buiWu.append(ameWu, ignore_index=True)\n",
    "# Wuhan = Wuhan.append(touWu, ignore_index = True)\n",
    "# Wuhan = Wuhan.append(higWu, ignore_index = True)\n",
    "# Wuhan.to_csv('Wuhan.csv', index = False)  \n",
    "Wuhan = pd.read_csv('Wuhan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "734c3e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "buiR = pd.read_csv('buildiingR3.csv', delimiter=\";\")\n",
    "buiR = buiR.iloc[:,0:5]\n",
    "ameR = pd.read_csv('amenityR3.csv', delimiter=\";\")\n",
    "ameR = ameR.iloc[:,0:5]\n",
    "touR = pd.read_csv('highwayR3.csv', delimiter=\";\")\n",
    "touR = touR.iloc[:,0:5]\n",
    "higR = pd.read_csv('tourismR3.csv', delimiter=\";\")\n",
    "higR = higR.iloc[:,0:5]\n",
    "Roma = buiR.append(ameR, ignore_index=True)\n",
    "Roma = Roma.append(touR, ignore_index = True)\n",
    "Roma = Roma.append(higR, ignore_index = True)\n",
    "Roma = Roma.drop(Roma[(Roma['error'] != 'no') & (Roma['error'] != 'yes')].index)\n",
    "Roma.to_csv('Roma.csv', index = False)  \n",
    "Roma = pd.read_csv('Roma.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f039296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buiSC = pd.read_csv('buildingSC3.csv', delimiter=\";\")\n",
    "# buiSC = buiSC.iloc[:,0:5]\n",
    "# ameSC = pd.read_csv('amenitySC3.csv', delimiter=\";\")\n",
    "# ameSC = ameSC.iloc[:,0:5]\n",
    "# touSC = pd.read_csv('highwaySC3.csv', delimiter=\";\")\n",
    "# touSC = touSC.iloc[:,0:5]\n",
    "# higSC = pd.read_csv('tourismSC3.csv', delimiter=\";\")\n",
    "# higSC = higSC.iloc[:,0:5]\n",
    "# Cairo = buiSC.append(ameSC, ignore_index=True)\n",
    "# Cairo = Cairo.append(touSC, ignore_index = True)\n",
    "# Cairo = Cairo.append(higSC, ignore_index = True)\n",
    "# Cairo.to_csv('Cairo.csv', index = False)  \n",
    "Cairo = pd.read_csv('Cairo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9346f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buiO = pd.read_csv('buildingO3.csv', delimiter=\";\")\n",
    "# buiO = buiO.iloc[:,0:5]\n",
    "# ameO = pd.read_csv('amenityO3.csv', delimiter=\";\")\n",
    "# ameO = ameO.iloc[:,0:5]\n",
    "# higO = pd.read_csv('highwayO3.csv', delimiter=\";\")\n",
    "# higO = higO.iloc[:,0:5]\n",
    "# Otawa = buiO.append(ameO, ignore_index=True)\n",
    "# Otawa = Otawa.append(higO, ignore_index = True)\n",
    "# Otawa.to_csv('Otawa.csv', index = False)  \n",
    "Otawa = pd.read_csv('Otawa.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b16e33",
   "metadata": {},
   "source": [
    "### We create the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e8ddaf9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def error(dataset, deli):\n",
    "    data = pd.read_csv(dataset, delimiter = deli)\n",
    "    # data = pd.read_csv('Wuhan.csv', delimiter = ',')\n",
    "    index = data.iloc[:,0]\n",
    "    obj = data['error']\n",
    "    data = data[['alpha','alphap']]\n",
    "    data1 = list(data['alpha'])\n",
    "    data2 = list(data['alphap'])\n",
    "    file = open(\"dict_all.obj\",'rb')\n",
    "    dict_all_loaded = pickle.load(file)\n",
    "    file = open(\"target.obj\",'rb')\n",
    "    dict_obj_loaded = pickle.load(file)\n",
    "    file.close()\n",
    "    file.close()\n",
    "    for col in data.columns[0:2]:\n",
    "            data.replace(dict_all_loaded[col], inplace=True)\n",
    "    data['aux1']=data1 \n",
    "    data['aux2']=data2        \n",
    "    def get_key(val):\n",
    "        for key, value in dict_obj_loaded.items():\n",
    "             if val == value:\n",
    "                 return key\n",
    "        return \"key doesn't exist\"\n",
    "    rf = joblib.load(\"./random_forest.joblib\")\n",
    "    lista = []\n",
    "    for i in range(len(data)):\n",
    "            if data.iloc[i,3][0:5] == 'name:':\n",
    "                lista.append(np.array([dict_obj_loaded['no']]))\n",
    "            elif data.iloc[i,3][0:5] == 'fuel:':\n",
    "                lista.append(np.array([dict_obj_loaded['no']])) \n",
    "            elif data.iloc[i,3][0:12] == 'description:':\n",
    "                lista.append(np.array([dict_obj_loaded['no']]))   \n",
    "            elif data.iloc[i,3][0:4] == 'ref:':\n",
    "                lista.append(np.array([dict_obj_loaded['no']]))   \n",
    "            elif data.iloc[i,3][0:8] == 'network:':\n",
    "                lista.append(np.array([dict_obj_loaded['no']]))  \n",
    "            elif data.iloc[i,3][0:10] == 'recycling:':\n",
    "                lista.append(np.array([dict_obj_loaded['no']]))\n",
    "            elif data.iloc[i,3][0:9] == 'currency:':\n",
    "                lista.append(np.array([dict_obj_loaded['no']]))\n",
    "            elif data.iloc[i,3][0:9] == 'alt_name:':\n",
    "                lista.append(np.array([dict_obj_loaded['no']])) \n",
    "            elif data.iloc[i,3][0:7] == 'source:':\n",
    "                lista.append(np.array([dict_obj_loaded['no']]))                 \n",
    "            elif data.iloc[i,3][0:8] == 'surface:':\n",
    "                lista.append(np.array([dict_obj_loaded['no']]))              \n",
    "            elif data.iloc[i,3][0:8] == 'contact:':\n",
    "                lista.append(np.array([dict_obj_loaded['no']])) \n",
    "            elif data.iloc[i,3][0:10] == 'wikipedia:':\n",
    "                lista.append(np.array([dict_obj_loaded['no']])) \n",
    "            elif data.iloc[i,3][0:9] == 'wikidata:':\n",
    "                lista.append(np.array([dict_obj_loaded['no']]))\n",
    "            elif data.iloc[i,3][0:8] == 'massgis:':\n",
    "                lista.append(np.array([dict_obj_loaded['no']]))  \n",
    "            elif data.iloc[i,3][0:9] == 'wikidata:':\n",
    "                lista.append(np.array([dict_obj_loaded['no']]))\n",
    "            elif data.iloc[i,3][0:11] == 'short_name:':\n",
    "                lista.append(np.array([dict_obj_loaded['no']]))     \n",
    "            elif data.iloc[i,3][0:5] == 'gnis:':\n",
    "                lista.append(np.array([dict_obj_loaded['no']]))               \n",
    "            elif data.iloc[i,3][0:5] == 'addr:' and data.iloc[i,3] != 'addr:housename' and data.iloc[i,2] != 'highway':\n",
    "                lista.append(np.array([dict_obj_loaded['no']])) \n",
    "            elif data.iloc[i,1] not in list(dict_all_loaded.get('alphap').values()):\n",
    "                lista.append(np.array([dict_obj_loaded['yes']]))\n",
    "            else:\n",
    "                pred = pd.DataFrame(data.iloc[i,0:2]).T\n",
    "                a = rf.predict(pred)\n",
    "                lista.append(a)\n",
    "\n",
    "    lista1=[]\n",
    "    for i in lista: lista1.append(i[0])\n",
    "    obj1 = [dict_obj_loaded[x] for x in obj]\n",
    "    list2 = []\n",
    "    for i in lista1:\n",
    "        list2.append(get_key(i))\n",
    "    df = {'ID': index, 'Error': list2, 'Error real': obj}\n",
    "    df = pd.DataFrame(df)\n",
    "#     print(df)\n",
    "#     print(accuracy_score(lista1,obj1))\n",
    "#     print(confusion_matrix(obj1, lista1))\n",
    "    return(df,accuracy_score(lista1,obj1),recall_score(lista1,obj1),\n",
    "           f1_score(lista1,obj1),confusion_matrix(obj1, lista1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b9c61f",
   "metadata": {},
   "source": [
    "### We check the quality of the results in Rome example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0c3b43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(             ID Error Error real\n",
       " 0    1447566610    no         no\n",
       " 1    1447566610   yes        yes\n",
       " 2    1447566610   yes        yes\n",
       " 3    1447566610    no         no\n",
       " 4    1447566610    no         no\n",
       " ..          ...   ...        ...\n",
       " 649   272424396   yes        yes\n",
       " 650   568345929    no         no\n",
       " 651   657433410   yes        yes\n",
       " 652   657433410   yes        yes\n",
       " 653   657433410   yes        yes\n",
       " \n",
       " [654 rows x 3 columns],\n",
       " 0.9694189602446484,\n",
       " 0.9299065420560748,\n",
       " 0.952153110047847,\n",
       " array([[435,  15],\n",
       "        [  5, 199]], dtype=int64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error('Roma.csv',',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
